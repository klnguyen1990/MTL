{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from nnunet.inference.predict import load_model_and_checkpoint_files\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "#os.system('jupyter nbconvert --to python Pytorch_model.ipynb')\n",
    "from Pytorch_model import nnUnet, Multitask_nnUNet\n",
    "\n",
    "#os.system('jupyter nbconvert --to python Pytorch_train_multitask.ipynb')\n",
    "from Pytorch_train_multitask import train, evaluation\n",
    "\n",
    "seed = 0\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA\n",
    "dim = (32*4, 32*3, 32*6)\n",
    "spacing = 4\n",
    "\n",
    "#IMAGE GENERATOR\n",
    "scale = (0.80, 1.20)\n",
    "sigma = (0.3, 0.8)\n",
    "task = '001' # pretrained nnUnet -> 001 : PET SUV - 002 : PET sans SUV - 003 - PET CT 2 Channels - 004 - PET CT Fusion\n",
    "\n",
    "#MODELE\n",
    "learning_rate = 1e-4\n",
    "score_weight = 3\n",
    "drop_encode = 0.5\n",
    "l1_lambda_fc1, l2_lambda_fc1 = 1e-3, 1e-3\n",
    "weight_decay = 3e-5\n",
    "\n",
    "batch_size = 1\n",
    "nb_epoch = 40\n",
    "num_workers = 10\n",
    "patience = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = '/media/nguyen-k/nnUNet_trained_models/nnUNet/3d_fullres'\n",
    "list_task = os.listdir(base)\n",
    "\n",
    "for t in list_task :\n",
    "    if task in t :\n",
    "        folders = os.path.join(base, t, 'nnUNetTrainerV2__nnUNetPlansv2.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind_list in range(1) : \n",
    "\n",
    "    test = 'Multitask_PET_L'+str(ind_list)\n",
    "    dir_base = '/home/nguyen-k/Bureau/segCassiopet2/Comparatif/Archives_MTL3/'+test\n",
    "    try:\n",
    "        os.mkdir(dir_base)\n",
    "    except OSError as error: \n",
    "        print(error) \n",
    "\n",
    "    path_list = '/home/nguyen-k/Bureau/segCassiopet/List_Patient_'+str(ind_list)\n",
    "    list_test = list(np.load(path_list + '/Test/list_test.npy'))\n",
    "    test_label_classe = np.load(path_list + '/Test/test_label_classe.npy')   \n",
    "    test_prob = np.zeros((len(list_test), 3))\n",
    "    np.save(dir_base+'/list_test.npy', list_test)\n",
    "    np.save(dir_base+'/test_label_classe.npy', test_label_classe)\n",
    "\n",
    "    for fold in range(1, 6) :\n",
    "        print('LIST PATIENT', ind_list, ' - FOLD', fold)  \n",
    "\n",
    "        dir_p = dir_base+'/Fold'+str(fold)\n",
    "        dir_p_1 = dir_p+'/Fig_seg_val'\n",
    "        dir_p_2 = dir_p+'/Fig_seg_test'\n",
    "        \n",
    "        try:\n",
    "            os.mkdir(dir_p)\n",
    "        except OSError as error: \n",
    "            print(error) \n",
    "\n",
    "        try:\n",
    "            os.mkdir(dir_p_1)\n",
    "        except OSError as error:\n",
    "            print(error)\n",
    "\n",
    "        try:\n",
    "            os.mkdir(dir_p_2)\n",
    "        except OSError as error:\n",
    "            print(error)\n",
    "        \n",
    "        #TRAIN     \n",
    "        trainer, params_tr = load_model_and_checkpoint_files(folders, folds=None, mixed_precision=None, checkpoint_name=\"model_best\")\n",
    "\n",
    "        nn_Unet = nnUnet(trainer.network)\n",
    "        state_dict = trainer.network.state_dict()\n",
    "        nn_Unet.load_state_dict(state_dict)\n",
    "        MultitaskNet = Multitask_nnUNet(nn_Unet, drop_encode=drop_encode, n_classes=3).cuda()   \n",
    "        \n",
    "        train(fold, MultitaskNet, nb_epoch, score_weight, l1_lambda_fc1, l2_lambda_fc1, dim, spacing, scale, sigma, \n",
    "                    num_workers, drop_encode, batch_size, learning_rate, patience, weight_decay, dir_p, path_list, seed)\n",
    "\n",
    "        #EVALUATION\n",
    "        print('LIST PATIENT', ind_list, ' - FOLD', fold, ' - VALIDATION')\n",
    "        path_train_val = os.path.join(path_list, 'Fold'+ str(fold))\n",
    "        list_val = list(np.load(path_train_val+'/list_val.npy'))\n",
    "        val_label_classe = np.load(path_train_val+'/val_label_classe.npy')\n",
    "        evaluation(MultitaskNet, list_val, val_label_classe, scale, sigma, dim, spacing, num_workers, dir_p_1)\n",
    "\n",
    "        #TEST\n",
    "        print('LIST PATIENT', ind_list, ' - FOLD', fold, ' - TEST')\n",
    "        test_prob = evaluation(MultitaskNet, list_test, test_label_classe, scale, sigma, dim, spacing, num_workers, dir_p_2)\n",
    "        np.save(os.path.join(dir_p, 'test_prob.npy'), test_prob)\n",
    "        print(' ')        \n",
    "\n",
    "        del MultitaskNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get results for ensemble method (average proba prediction over 5 folds)\n",
    "os.system('jupyter nbconvert --to python roc_Precision_Recall.ipynb')\n",
    "from roc_Precision_Recall import *\n",
    "\n",
    "for ind_list in range(1) : \n",
    "\n",
    "    print('LIST PATIENT', ind_list)  \n",
    "\n",
    "    test = 'Multitask_PET_L'+str(ind_list)\n",
    "    dir_base = '/home/nguyen-k/Bureau/segCassiopet2/Comparatif/Archives_MTL3/'+test\n",
    "\n",
    "    fold = 1\n",
    "    dir_p = dir_base+'/Fold'+str(fold)\n",
    "    sum = np.load(os.path.join(dir_p, 'test_prob.npy'))\n",
    "\n",
    "    path_list = '/home/nguyen-k/Bureau/segCassiopet2/List_Patient_'+str(ind_list)\n",
    "    list_test = list(np.load(path_list + '/Test/list_test.npy'))\n",
    "    test_label_classe = np.load(path_list + '/Test/test_label_classe.npy')   \n",
    "    test_label_classe = np.array(test_label_classe, dtype=np.uint8)\n",
    "\n",
    "    for fold in range(2, 6) :\n",
    "        dir_p = dir_base+'/Fold'+str(fold)\n",
    "        test_prob = np.load(os.path.join(dir_p, 'test_prob.npy'))\n",
    "        sum += test_prob\n",
    "\n",
    "    test_prob = sum / 5\n",
    "\n",
    "    pred = np.zeros(test_label_classe.shape[0])\n",
    "    for i in range(test_label_classe.shape[0]) : \n",
    "        pred[i] = np.argmax(test_prob[i])\n",
    "\n",
    "    mat_label = np.zeros((test_label_classe.shape[0],3))\n",
    "    for i in range(test_label_classe.shape[0]) :\n",
    "        mat_label[i, int(test_label_classe[i])] = 1\n",
    "\n",
    "    roc_auc, fpr, tpr = compute_ROC_auc(y_label=mat_label,y_predicted=test_prob,n_classes=3)\n",
    "    plt.clf()\n",
    "    plot_ROC_curve(fpr,tpr,roc_auc,classe=0,color='blue')\n",
    "    plot_ROC_curve(fpr,tpr,roc_auc,classe=1,color='red')\n",
    "    plot_ROC_curve(fpr,tpr,roc_auc,classe=2,color='black')\n",
    "    plt.savefig(dir_base+'/ROC.png')\n",
    "\n",
    "    precision, recall,average_precision = compute_precision_recall(y_label=mat_label,y_predicted=test_prob,n_classes=3)\n",
    "    plot_precision_recall_curve(precision, recall, average_precision,n_classes=2,color=['blue','red','black'])\n",
    "    plt.savefig(dir_base+'/AUC.png')\n",
    "\n",
    "    print('Micro F1 score ', f1_score(y_true=test_label_classe, y_pred=pred, average='micro'))\n",
    "    print('Macro F1 score ', f1_score(y_true=test_label_classe, y_pred=pred, average='macro'))\n",
    "    print('Weighted F1 score ', f1_score(y_true=test_label_classe, y_pred=pred, average='weighted'))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
